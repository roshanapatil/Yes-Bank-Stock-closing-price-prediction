{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "beRrZCGUAJYm",
        "mDgbUHAGgjLW",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "F6T5p64dYrdO",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "fF3858GYyt-u",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "49K5P_iCpZyH",
        "kLW572S8pZyI",
        "578E2V7j08f6",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshanapatil/Yes-Bank-Stock-closing-price-prediction/blob/main/Yes_Bank_Stock_Closing_Price_Prediction_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Yes_Bank_Stock_Closing_Price_Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1**   - Roshana Patil"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words.\n",
        "\n",
        "Yes Bank Limited is an Indian Private Sector bank headquartered in Mumbai, India and was\n",
        "founded by Rana Kapoor and Ashok Kapoor in 2004.The Yes Bank stock market is a dynamic\n",
        "and volatile industry and Investors generally decide to buy or sell the stock based on\n",
        "company’s past and present performance.\n",
        "\n",
        "But the stock price of Yes bank was actually fall from 2018 onwards which shows the impact of\n",
        "the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that\n",
        "impacted the stock prices of the company and whether any predictive models can do justice to\n",
        "such situations. This dataset has monthly stock prices of the bank since its inception and\n",
        "includes Closing, Opening (Starting), Highest, and Lowest stock prices of every month.\n",
        "\n",
        "The Main objective is to predict the stock’s closing price of the month. We have to build models\n",
        "which help us to predict the future stock prices. \n",
        "\n",
        "I have applied various Regression Models in Our YES-Bank-Stock-Price-Prediction such as\n",
        "follows:-\n",
        "1. Linear Regression.\n",
        "2. Lasso Regression (with and without Cross Validation)\n",
        "3. Ridge Regression (with and without Cross Validation)\n",
        "4. Elastic Net Using Cross Validation\n",
        "**Some insights**:-\n",
        "1. Dependent variable (Close) is highly correlated with other Independent Variables.\n",
        "2. We have seen that there are neither null nor duplicate values. But “Date” feature has values\n",
        "of object data type. So, we converted it into proper date format YYYY-MM-DD.\n",
        "3. With the help of Visualization, we have seen that from 2018 onwards there is sudden fall in\n",
        "the stock closing price. It makes sense how severely Rana Kapoor case fraud affected the\n",
        "price of Yes Bank Stocks.\n",
        "4. With the help of distribution plot, we see that our data is positively skewed. So, we apply\n",
        "some kind of transformation i.e. Log Transformation to convert it into a normal distribution."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/roshanapatil/Yes-Bank-Stock-closing-price-prediction.git"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month. The main objective is to predict the stock’s closing price of the month.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels"
      ],
      "metadata": {
        "id": "My_Q3Wnc9lSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np                #  Import numpy for mathematical calculation\n",
        "import pandas as pd               #  Import pandas for data wrangling\n",
        "import matplotlib.pyplot as plt   #  Import matplotlib and seaborn for Data Visualization\n",
        "import seaborn as sns\n",
        "from datetime import datetime     # Import datetime to convert date column into proper format\n",
        "\n",
        "# This method is used to split the dataset into training and test set while buliding the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import different models for prediction\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet \n",
        "\n",
        "# import matrix module to evaluate the performance of the model\n",
        "from sklearn.metrics import *\n",
        "import pandas.util.testing as tm\n",
        "\n",
        "# import variance_inflation_factor method to reduce multicollinearity in independent variables\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "url='''https://raw.githubusercontent.com/roshanapatil/Yes-Bank-Stock-closing-price-prediction/main/data_YesBank_StockPrices%20(1).csv'''\n",
        "yes_bank_df=pd.read_csv(url)"
      ],
      "metadata": {
        "id": "iDdKpHHYvUFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yes_bank_df"
      ],
      "metadata": {
        "id": "qIZ09B4XwGLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "yes_bank_df.head()\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "yes_bank_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "yes_bank_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking for NULL and Duplicate values"
      ],
      "metadata": {
        "id": "EPFIYQQNh0W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "yes_bank_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no duplicate value in our dataset"
      ],
      "metadata": {
        "id": "thQ4hp3BpSj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "yes_bank_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "sns.heatmap(yes_bank_df.isnull(), cbar=True)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Till now we get to know the following points about our dataset:\n",
        "\n",
        "There is 185 rows and 5 cloumns in our dataset.\n",
        "\n",
        "There are no mising values and duplicate values in the dataset.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "yes_bank_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "yes_bank_df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a dataset of YES BANK which contain monthly stock prices of bank since its opening.It contain multiple features like:-\n",
        "\n",
        "Date :- Date denotes the date of investment(date contains month and year for a particular price) (Object)\n",
        "\n",
        "Open :- means the price at which a stock started trading (Numerical).\n",
        "\n",
        "High :-The high is the highest price at which a stock traded during a period (Numerical).\n",
        "\n",
        "Low :-The low is the minimum price at which a stock traded during a period (Numerical).\n",
        "\n",
        "Close :- The closing price refers to a stock's trading price closed at  end of a trading day (Numerical).It's a dependent variable which we need to predict from our respetive ML models.The closing price is calculated as the weighted average price of the last 30 minutes, i.e. from 3:00 PM to 3:30 PM in case of equity."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for col in yes_bank_df.columns:\n",
        "  print(\"No. of unique values in \",col,\"is\",yes_bank_df[col].nunique())"
      ],
      "metadata": {
        "id": "Sk9VqJaZxN0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# creating a copy of dataframe so that our original dataset not afect\n",
        "stock_price_df= yes_bank_df.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if there is any null value or not\n",
        "\n",
        "stock_price_df.isnull().sum()"
      ],
      "metadata": {
        "id": "1vuR_BZTwDfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no NULL value in the dataset"
      ],
      "metadata": {
        "id": "1-L6FgbcwQWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for any duplicate row or not\n",
        "len(stock_price_df[stock_price_df.duplicated()])\n",
        "     \n"
      ],
      "metadata": {
        "id": "ZQ2RxRoiwgy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no DUPLICATE value in the dataset"
      ],
      "metadata": {
        "id": "UwhhHS3Zws3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the first five dataset \n",
        "stock_price_df.head()"
      ],
      "metadata": {
        "id": "cESwhCIwCiC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "stock_price_df.shape"
      ],
      "metadata": {
        "id": "Io-A4VMACsbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_price_df.corr()"
      ],
      "metadata": {
        "id": "ir9cnUzZUcLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stock_price_df.describe(include='all') "
      ],
      "metadata": {
        "id": "YIFpuHxUFDUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the format of \"Date\" column\n",
        "\n",
        "stock_price_df['Date']\n",
        "     "
      ],
      "metadata": {
        "id": "GhlV8WETA_L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above output,We have seen that the format of Date is \"MMMM-YY\" .So we need to convert in proper date format \"YYYY-MM-DD\". Also,convert year into numeric format .\n",
        "\n"
      ],
      "metadata": {
        "id": "1BFW7eXUtHkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting 'Date' into datetime - 'YYYY-MM-DD' format\n",
        "# Using Pandas to_datetime() method helps to convert string Date time into Python Date time object\n",
        "# Apply lambda function to convert  all values of date column to proper format \n",
        "stock_price_df['Date'] = pd.to_datetime(stock_price_df['Date'].apply(lambda x: datetime.strptime(x, '%b-%y')))\n",
        "stock_price_df['Date'] "
      ],
      "metadata": {
        "id": "haH2JwQ9Aqcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make \"Date\" column as index of the dataframe\n",
        "\n",
        "stock_price_df.set_index('Date', inplace=True)\n",
        "     "
      ],
      "metadata": {
        "id": "bJrKoB_51MPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the changes \n",
        "\n",
        "stock_price_df.tail()"
      ],
      "metadata": {
        "id": "NGPUAC8L1RG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now only 4 columns are left in the respective dataframe\n",
        "\n",
        "stock_price_df.info()\n",
        "     "
      ],
      "metadata": {
        "id": "41evOkMu2GR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating dependent and independent variables\n"
      ],
      "metadata": {
        "id": "f6r9vsiQuQdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dependent variable i.e 'Y'\n",
        "\n",
        "dependent_variable = stock_price_df.iloc[:,-1]  # use iloc method of the dataframe to select only dependent variable i.e. last column\n",
        "dependent_variable.values   # print column values into an array"
      ],
      "metadata": {
        "id": "B9jcRYkLxdzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of independent variables i.e x1,x2,x3,.....xn\n",
        "\n",
        "independent_variables = stock_price_df.iloc[:,:-1] # use iloc method of the dataframe to select all independent variable i.e. except last column\n",
        "independent_variables"
      ],
      "metadata": {
        "id": "nq5t1LPbxqhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating list of numerical and categorical columns\n",
        "numerical_columns=[]\n",
        "for col in stock_price_df.columns:\n",
        "  if stock_price_df[col].nunique()>5:\n",
        "    numerical_columns.append(col)\n",
        "categorical_columns=list(set(stock_price_df.columns)-set(numerical_columns))"
      ],
      "metadata": {
        "id": "YtS4ItFlzCoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(numerical_columns)"
      ],
      "metadata": {
        "id": "Cp3XHUquzeYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(categorical_columns)"
      ],
      "metadata": {
        "id": "gHg4OSDizisY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We creat a copy from the dataframe beacause origanal data is not affected .\n",
        "\n",
        "Every feature is extremely corelated with each other, so taking just one feature or average of these features would suffice for our regression model as linear regression assumes there is no multi colinearity in the features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to visualize each chart properly we will do data visualization in a structured way following ' UBM ' rule:\n",
        "\n",
        "Univariate Analysis\n",
        "\n",
        "Bivariate Analysis\n",
        "\n",
        "Multivariate Analysis"
      ],
      "metadata": {
        "id": "4S8_RZQ6KSVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Univariate Analysis**"
      ],
      "metadata": {
        "id": "OKB-GhA5KVhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent variable 'Closing price'\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.distplot(stock_price_df['Close'],color=\"b\")\n",
        "plt.title('Close Data Distribution')\n",
        "plt.xlabel('Closing Price')\n",
        "plt.show()\n",
        "# Dependent variable 'Close' price of a stock\n",
        "#Convert it into Normal Distribution using Log Transformation.\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.distplot(np.log10(stock_price_df['Close']),color=\"b\")"
      ],
      "metadata": {
        "id": "ItXWr-Oy7cbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Numerical Features"
      ],
      "metadata": {
        "id": "Rbwza2bwm1XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the numerical columns in dataset\n",
        "\n",
        "numeric_features = stock_price_df.describe().columns\n",
        "numeric_features\n",
        "     "
      ],
      "metadata": {
        "id": "iKXlH-1aB-vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the  closing price distribution and numerical futures."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above distibution is not a Normal Distribution.It's a Positively Skewed Distribution .So,We need to convert it into Normal Distribution using Log Transformation.\n",
        "\n",
        "using log transformation it is not a perfect Normal Distribution Graph but it looks like Normal Distribution Graph.\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking the Distribution and Outliers\n"
      ],
      "metadata": {
        "id": "et6JRJ5Uorjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # plot a bar plot for each numerical feature count \n",
        "\n",
        "for col in numeric_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.distplot(stock_price_df[col], color=\"blue\")\n",
        "\n",
        "# The Axes. axvline() function in axes module of matplotlib library is used to add a vertical line across the axis.\n",
        "# It will show where the \"mean\" and \"median\" lie for each plot  \n",
        "\n",
        "    plt.ylabel(\"Count\", size=10)\n",
        "    plt.axvline(stock_price_df[col].mean(),color='magenta',linewidth=1.5)\n",
        "    plt.axvline(stock_price_df[col].median(),color='red',linestyle=\"dashed\",linewidth=1.5)\n",
        "# create boxplot to see if there is any outliers in any column or not\n",
        "# use subplot() function of matplotlib to create boxplot in this figure itself\n",
        "# box plot is used to check outliers are present in respective features or not\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(y=stock_price_df[col], color=\"green\")\n",
        " \n",
        "plt.show()\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the distribution and outliers."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above graph shows that they are not a normal distribution curve.\n",
        "\n",
        "The mean and median should be equal for perfect normal distribution curve.But, mean is not equal to median as there is not a perfect normal distribution curve.\n",
        "Outliers are present in each column.\n",
        "\n",
        "We need to convert all the features to normal distribution using log transformation.\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Log tranformation to convert features to Normal Distribution"
      ],
      "metadata": {
        "id": "Nu8JfrvNuXDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using log tranformation  convert a column to normal distribution\n",
        "\n",
        "for col in numeric_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Distribution Curve\")\n",
        "\n",
        "# np.log() is a method in numpy library to convert our dataset values into log transformation to get a normal distribution curve\n",
        "\n",
        "    feature_to_log = np.log(stock_price_df[col])  # assign log tranformation value into a variable \n",
        "    sns.distplot(feature_to_log, color=\"blue\")\n",
        "\n",
        "# The Axes. axvline() function in axes module of matplotlib library is used to add a vertical line across the axis.\n",
        "# It will show where the \"mean\" and \"median\" lie for each plot  \n",
        "\n",
        "    plt.ylabel(\"Count\", size=14)\n",
        "    plt.axvline(feature_to_log.mean(),color='magenta',linewidth=1.5)\n",
        "    plt.axvline(feature_to_log.median(),color='red',linestyle=\"dashed\",linewidth=1.5)\n",
        "# create boxplot to remove the outliers \n",
        "# use subplot() function of matplotlib to create boxplot in this figure itself\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(y=feature_to_log, color=\"green\")\n",
        " \n",
        "plt.show()\n",
        "     \n"
      ],
      "metadata": {
        "id": "MPQApPBKEnQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the normal distriution and outlier."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above graph, We see that now our graph is nearly close to normal distribution.\n",
        "\n",
        "Mean is nearly equal to median.\n",
        "\n",
        "Median is shown by dashed line.\n",
        "\n",
        "From the box plot, We see that outliers are removed by log transformation.\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check how the different stock price vary after fraud case 2018"
      ],
      "metadata": {
        "id": "ztd1gNuEqPem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization \n",
        "# Line plot to see how the \"Open\" and \"Close\" stock price of Yes Bank is affected after 2018 fraud case\n",
        "\n",
        "stock_price_df[['Open','Close']].plot(kind='line',ylabel=\"Price\",figsize=(10,6))"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check how the different stock price vary after fraud case 2018"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above scatter graph ,We conclude that the highest and lowest stock price is keep on increasing till 2018.\n",
        "\n",
        "But after 2018 , the stock price is keep on decreasing due the fraud case involving Rana Kapoor."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization \n",
        "# Check how the \"High\" and \"Low\" stock are affected after 2018 fraud case\n",
        "\n",
        "stock_price_df[['High','Low']].plot(kind='line',ylabel=\"Price\",figsize=(10,6))"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check how the different stock price vary after fraud case 2018"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We conclude that the highest and lowest stock price is keep on increasing till 2018.\n",
        "\n",
        "But after 2018, the stock price is keep on decreasing due the fraud case involving"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Bivariate Analysis**"
      ],
      "metadata": {
        "id": "yP1Z4ZNOKj47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 "
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Checking correlation between dependent vs independent variable**"
      ],
      "metadata": {
        "id": "GxmO4-wOOhQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find correlation betweeen different dependent variables \"Close\" to all independent variable\n",
        "for col in numeric_features[0:-1]: \n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = stock_price_df[col]\n",
        "    label = stock_price_df['Close']\n",
        "    correlation = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Close')\n",
        "    ax.set_title('Close vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(stock_price_df[col], stock_price_df['Close'], 1)\n",
        "    y_hat = np.poly1d(z)(stock_price_df[col])\n",
        "\n",
        "    plt.plot(stock_price_df[col], y_hat, color=\"blue\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3V45srK2KeaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking correlation between dependent vs independent variable\n",
        "\n"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above graphs depicts that there is high correlation between dependent(Close) and independent(High,Low,Open) features.\n",
        "\n",
        "We try to reduce the correlation for better prediction of the model.\n",
        "\n",
        "We calculate the VIF factor to reduce the multicollinearity between independent variables."
      ],
      "metadata": {
        "id": "Rn8Ed5S1OzX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Multivariate Analysis**"
      ],
      "metadata": {
        "id": "4DZTcfe8P4fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use Heat Map to show correlation between all variables"
      ],
      "metadata": {
        "id": "e86MNbx3UHL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Correlation between each and every column of the dataframe\n",
        "plt.figure(figsize = (15,10))\n",
        "sns.heatmap(stock_price_df.corr(),annot= True,cmap='Greens')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wanted to check insights of  correlation between two variables in the dataset so we choosen this chart(Heatmap)."
      ],
      "metadata": {
        "id": "_bP5LMuRQINX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highest positive correlation in this heatmap are 'Open' and 'High'\n",
        "and highest negative correlation are 'Open' and 'Close' variable."
      ],
      "metadata": {
        "id": "nsZDcvazPLXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot the entire dataframe using PairGrid and checking the relation between variables\n"
      ],
      "metadata": {
        "id": "_eBHHTUzUqZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# It plot each and every column of our df with other column\n",
        "\n",
        "colors = iter(['xkcd:red purple', 'xkcd:pale teal', 'xkcd:warm purple',\n",
        "       'xkcd:light forest green', 'xkcd:blue with a hint of purple',\n",
        "       'xkcd:light peach', 'xkcd:dusky purple', 'xkcd:pale mauve',\n",
        "       'xkcd:bright sky blue', 'xkcd:baby poop green', 'xkcd:brownish',\n",
        "       'xkcd:moss green', 'xkcd:deep blue', 'xkcd:melon',\n",
        "       'xkcd:faded green', 'xkcd:cyan', 'xkcd:brown green',\n",
        "       'xkcd:purple blue', 'xkcd:baby shit green', 'xkcd:greyish blue'])\n",
        "def my_scatter(x,y, **kwargs):\n",
        "    kwargs['color'] = next(colors)\n",
        "    plt.scatter(x,y, **kwargs)\n",
        "\n",
        "def my_hist(x, **kwargs):\n",
        "    kwargs['color'] = next(colors)\n",
        "    plt.hist(x, **kwargs)\n",
        "g = sns.PairGrid(stock_price_df)\n",
        "g.map_diag(my_hist)\n",
        "g.map_offdiag(my_scatter)"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "phNSCfzFPByo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the correlation among variables using pair plot "
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "FN4ktelEPHyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High Correlation among the variable."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "78YCyOWoPL53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "lYqSq3OBPQz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 "
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 14 visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "u1TBUBKusfj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "XI3PGKbNtBxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Chart - 15"
      ],
      "metadata": {
        "id": "Rb5rqSCDtbCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Chart - 15 visualization code\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "eHQiyhgPVB6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "sIMU0L2_VE_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "h5w4OLkVxUSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "#Already handle"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "#Already handle"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "C7r-xMirwXa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "     \n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n"
      ],
      "metadata": {
        "id": "hMGuT4fWncWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multicollinearity"
      ],
      "metadata": {
        "id": "n-3Vg_vqzdxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multicollinearity\n",
        "# Calculate VIF(Variation Inflation Factor) to see the correlation between independent variables\n",
        "\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "i2WQCl0-zblN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(stock_price_df[[i for i in stock_price_df.describe().columns  if i not in ['Date','Close']]])"
      ],
      "metadata": {
        "id": "_pqQF44NzbIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIF scores are high so it implies that associated independent variables are highly collinear to each other in the dataset.\n",
        "\n",
        "As all the variables are equally important for closing stock price prediction, so I will not be performing any kind of feature engineering here.\n",
        "I am not removing any column because all the columns are equally important for prediction.\n",
        "\n",
        "Removing column lead to loss of valuable information(features) which are essential for accurate prediction for the model.It results in bad model.So,I am not deleting any featues form the dataset and try to predict the result and see how the model performs with multicollinearity and evaluate the performance of the model."
      ],
      "metadata": {
        "id": "suKdPWZbKBu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying zscore to each values of independent variable \n",
        "\n",
        "from scipy.stats import zscore  # zcore is used for scaling the data\n",
        "X = round(independent_variables.apply(zscore),3)\n",
        "     \n",
        "     "
      ],
      "metadata": {
        "id": "AnAosRCKPuip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying log on dependent variable \n",
        "\n",
        "Y = np.log10(dependent_variable)   "
      ],
      "metadata": {
        "id": "Eg5wcjPCKdAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to divide the dataset into two subsets.\n",
        "\n",
        "The first subset is used to fit the model and is referred to as the training dataset.\n",
        "\n",
        "The second subset is not used to train the model. This second dataset is referred to as the test dataset.\n",
        "\n",
        "Train Dataset : Used to fit the machine learning model.\n",
        "\n",
        "Test Dataset : Used to evaluate the fit machine learning model.\n"
      ],
      "metadata": {
        "id": "MggWvNsDK4hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our data into train and test datasets \n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state=0)\n",
        "print('X_train: ',X_train.shape)\n",
        "print('X_test: ',X_test.shape)\n",
        "     "
      ],
      "metadata": {
        "id": "m_brgy1iNbAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DataFrames of test and train dataset\n",
        "\n",
        "train_df = pd.DataFrame(X_train,Y_train)\n",
        "test_df = pd.DataFrame(Y_test)\n",
        "test_df.rename(columns = {'Close':'Actual Closing Price'},inplace = True)\n"
      ],
      "metadata": {
        "id": "UQqQAcUjNodu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create an empty dataframe for storing an evalution metrics for each regression model to compare the values which model will give best result\n"
      ],
      "metadata": {
        "id": "b123auotg_hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating empty data frame for each regression model \n",
        "i=0\n",
        "evaluation_metrices_df = pd.DataFrame()\n",
        "     "
      ],
      "metadata": {
        "id": "eUq8pcpmhIN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for evaluating all the metrices for the different models and call it when required\n",
        "\n",
        "def evaluation_metrics(Y_pred):\n",
        "  \"\"\"\n",
        "  This function is used to evaluate all the metrices for different algorithms used for models. It contain metrices\n",
        "  like Mean Square Error , Root Mean Square Error , R^2 , Adjusted R^2 \n",
        "  \"\"\"\n",
        "  MSE = mean_squared_error(Y_test,Y_pred)\n",
        "  print(\"Mean Squared Error: \",MSE)\n",
        "  RMSE = np.sqrt(MSE)\n",
        "  print(\"Root Mean Squared Error: \",RMSE)\n",
        "  r2 = r2_score(Y_test,Y_pred)\n",
        "  print(\"R2: \",r2)\n",
        "  adjusted_r2 = 1-(1-r2_score(Y_test,Y_pred))*(X_test.shape[0]-1)/((X_test.shape[0]-X_test.shape[1]-1))\n",
        "  print(\"Adjusted R2: \",adjusted_r2)\n",
        "  MAPE = mean_absolute_percentage_error(Y_test,Y_pred)\n",
        "  print(\"Mean Absolute Percentage Error: \",round(MAPE,4),\" %\" ) \n",
        "\n",
        "  \"\"\"  This function is also inserting evaluation metrices of each applied model in \n",
        "       empty dataframe create above named as \"evaluation_metrices_df\"  \n",
        "  \"\"\"\n",
        "\n",
        "  evaluation_metrices_df.loc[i,\"MSE\"] = round(MSE,4)\n",
        "  evaluation_metrices_df.loc[i,\"RMSE\"] = round(RMSE,4)\n",
        "  evaluation_metrices_df.loc[i,\"R2\"] = round(r2,4)\n",
        "  evaluation_metrices_df.loc[i,\"Adjusted R2\"]=round(adjusted_r2,4)\n",
        "  evaluation_metrices_df.loc[i,\"MAPE\"]=round(MAPE,4)\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "v1GVimuIhLe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create one function to plot graph between actual and predicted value of  dependent variable(Close)\n",
        "\n",
        "def plot_graph(Y_predicted):\n",
        "   \n",
        "   \"\"\" Plot scatter plot between actual close price vs predicted close price \"\"\"\n",
        "\n",
        "   plt.figure(figsize=(12,8))\n",
        "   plt.plot((Y_predicted),color=\"red\" )   # plot predicted values\n",
        "   plt.plot(np.array(Y_test))             # plot test values \n",
        "   plt.legend([\"Predicted\",\"Actual\"])\n",
        "   plt.ylabel(\"Price\")\n",
        "   plt.xlabel(\"Test data\")\n",
        "   plt.title(\"Actual Stock Close Price VS Predicted Stock Close Stock Price\")\n",
        "   plt.show()\n",
        "   return"
      ],
      "metadata": {
        "id": "0vx_IwEZihS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Linear Regression**"
      ],
      "metadata": {
        "id": "u2CojdpQplZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Implementing Linear regression to fit the model\n",
        "lin_reg = LinearRegression().fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding score get from training data\n",
        "\n",
        "lin_reg.score(X_train, Y_train)"
      ],
      "metadata": {
        "id": "4axUhXDZlKKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding regression cofficients\n",
        "lin_reg.coef_"
      ],
      "metadata": {
        "id": "_MDNHvTwlPWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intercept term\n",
        "\n",
        "lin_reg.intercept_"
      ],
      "metadata": {
        "id": "mBoVmXtrlR3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "# Predicting the values of Y(dependent variable) on the basis of test data\n",
        "\n",
        "Y_pred_linear = lin_reg.predict(X_test)\n",
        "# Printing Y predicted values in array form\n",
        "\n",
        "Y_pred_linear"
      ],
      "metadata": {
        "id": "a5_6yvbWkwJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding one column in test dataframe to see the difference between actual and predicted values\n",
        "\n",
        "test_df['LR Predicted Closing Price'] = Y_pred_linear\n",
        "test_df.head(10)\n",
        "     "
      ],
      "metadata": {
        "id": "32xwGgk-mQcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression is one of the most basic types of regression in\n",
        "supervised machine learning. The linear regression model consists of a predictor variable and a dependent variable related linearly to each other. We try to find the relationship between independent variable (input) and a corresponding dependent variable (output).\n"
      ],
      "metadata": {
        "id": "6jqzf_SEYAph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserting metrices for Linear Regression in the dataframe \n",
        "evaluation_metrices_df.loc[i,\"Model_Name\"]='Linear regression'\n",
        "\n",
        "# Calling evaluation matrix function for Linear Regression\n",
        "evaluation_metrics(Y_pred_linear)\n",
        "i+=1  # i is a incremented variable\n",
        "     "
      ],
      "metadata": {
        "id": "RW6ZbCipnBOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Call plot graph function to see the  difference in actual vs predicted values\n",
        "\n",
        "plot_graph(Y_pred_linear)\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our linear model predicted the close price with **0.032** Mean Squared Error.\n",
        "\n",
        "R^2 tell us that independent variable is able to describe **83.10%** of dependent variable\n",
        "\n",
        "Adjusted R^2 is approximately **82.12%**\n",
        "\n",
        "Mean Absolute Percentage Error is **0.0918 %**"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lasso Regression"
      ],
      "metadata": {
        "id": "6cY33F7_qBZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of **lasso regression** is to obtain the subset of predictors that minimizes prediction error for a quantitative response variable. The lasso does this by imposing a constraint on the model parameters that causes regression coefficients for some variables to shrink toward zero.\n",
        "\n"
      ],
      "metadata": {
        "id": "1_qBg7Qod69F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n"
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ML Model - 2 Implementation\n",
        "\n",
        "# Set hyperparameter  alpha value and fix maximum number of iteration \n",
        "\n",
        "lasso  = Lasso(alpha=0.0001 , max_iter= 3000)\n",
        "# Fit the Algorithm\n",
        "lasso.fit(X_train, Y_train)\n",
        "# Predict on the model\n",
        "lasso.score(X_train, Y_train)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing cofficients \n",
        "lasso.coef_\n",
        "     "
      ],
      "metadata": {
        "id": "TEB1NUFLrayO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predicting the values of Y(dependent variable) on the basis of test data\n",
        "\n",
        "Y_pred_lasso = lasso.predict(X_test)\n",
        "     \n",
        "\n",
        "# Printing Y predicted values in array form\n",
        "\n",
        "Y_pred_lasso"
      ],
      "metadata": {
        "id": "xTVJImwbrut2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Adding one column in test dataframe to see the difference between actual and predicted values\n",
        "\n",
        "test_df['Lasso Predicted Closing Price'] = Y_pred_lasso\n",
        "lasso_df = test_df.loc[:,['Actual Closing Price','Lasso Predicted Closing Price']]\n",
        "lasso_df.head(5)"
      ],
      "metadata": {
        "id": "7bIjXL9_r1RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserting metrices for Lasso Regression\n",
        "evaluation_metrices_df.loc[i,\"Model_Name\"]='Lasso regression'\n",
        "\n",
        "# Calling evaluation matrix function for Lasso Regression\n",
        "evaluation_metrics(Y_pred_lasso)\n",
        "i+=1  # i is a incremented variable"
      ],
      "metadata": {
        "id": "tDis04PwsFiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call plot graph function to see the  difference in actual vs predicted values\n",
        "\n",
        "plot_graph(Y_pred_lasso)"
      ],
      "metadata": {
        "id": "b86Py9Izsh4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our lasso model predicted the close price with **0.032** Mean Squared Error.\n",
        "\n",
        "R^2 tell us that independent variable is able to describe **83.14%** of dependent variable\n",
        "\n",
        "Adjusted R^2 is approximately **82.17%**\n",
        "\n",
        "Mean Absolute Percentage Error is **0.0918 %**"
      ],
      "metadata": {
        "id": "IAhu9cMKeHfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross Validation in Lasso Regression"
      ],
      "metadata": {
        "id": "QfixeRy-bV85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Validation** : In cross validation ,We divide our dataset into 3 parts\n",
        "training, validation and testing. The testing data is only for the final check, \n",
        "train and validation is used for the hyper parameter tuning in order to avoid the data leakage.\n",
        "\n",
        "**Hyperparameters** : are parameters whose values control the learning process and determine the values of model parameters that a learning algorithm ends up learning. For eg, alpha, cv"
      ],
      "metadata": {
        "id": "ujoUPXYUds3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Using Cross validation while implementing lasso regression\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV # Importing GridSearchCV for implementing cross validation\n",
        "lasso = Lasso() # Creating lasso object\n",
        "\n",
        "# estimating different alpha(hyper parameter) values and cross validation(cv) value is 5\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]} \n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=5)   \n",
        "lasso_regressor.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Algorithm\n",
        "# Finding bext alpha value to fit the model\n",
        "\n",
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "wU-o63-3s6Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "# Predicting the values of Y(dependent variable) on the basis of test data\n",
        "\n",
        "Y_pred_lasso_cv = lasso_regressor.predict(X_test)\n",
        "# Adding one column in test dataframe to see the difference between actual and predicted values\n",
        "\n",
        "test_df['Lasso Predicted Cross Validation Price'] = Y_pred_lasso_cv\n",
        "lasso_df = test_df.loc[:,['Actual Closing Price','Lasso Predicted Cross Validation Price']]\n",
        "lasso_df.head(5)\n",
        "     \n"
      ],
      "metadata": {
        "id": "kGVI4Y8ltDwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserting metrices for Lasso Regression CV\n",
        "evaluation_metrices_df.loc[i,\"Model_Name\"]='Lasso Regression CV'\n",
        "\n",
        "#  Calling evaluation matrix function for Lasso Regression with Cross validation\n",
        "evaluation_metrics(Y_pred_lasso_cv)\n",
        "i+=1 # i is a incremented variable"
      ],
      "metadata": {
        "id": "2MDwGZSAticJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call plot graph function to see the  difference in actual vs predicted values\n",
        "\n",
        "plot_graph(Y_pred_lasso_cv)\n",
        "     \n"
      ],
      "metadata": {
        "id": "Ae_XkvQNtssf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV hyperparameter optimization technique are used.\n",
        " In cross validation ,We divide our dataset into 3 parts training, validation and testing. The testing data is only for the final check, train and validation is used for the hyper parameter tuning in order to avoid the data leakage.\n",
        " \n",
        " Are parameters whose values control the learning process and determine the values of model parameters that a learning algorithm ends up learning. For eg, alpha, cv"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n"
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Validation in Lasso Regression\n",
        " predicted the close price with **0.032** Mean Squared Error.\n",
        "\n",
        "R^2 tell us that independent variable is able to describe **83.34%**of dependent variable\n",
        "\n",
        "Adjusted R^2 is approximately **82.38%**\n",
        "\n",
        "Mean Absolute Percentage Error is **0.0923 %**"
      ],
      "metadata": {
        "id": "TCxTNNHDwZMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Lasso Regression model using these evaluation metrics, businesses can gain insights into the accuracy of the model.\n",
        "\n",
        " A lower MSE, higher R² and Adjusted R², and lower MAPE indicate better model performance and can help businesses make more accurate predictions and better decisions."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ridge Regression with Cross Validation"
      ],
      "metadata": {
        "id": "56pYn_Q4uldt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Implementing Ridge regression with CV\n",
        "\n",
        "ridge = Ridge() # creating object\n",
        "\n",
        "# estimating different alpha values and cross validation(cv) value is 3\n",
        "\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train,Y_train)\n",
        "     \n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Algorithm\n",
        "# Finding bext alpha value to fit the model\n",
        "\n",
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)\n",
        "     "
      ],
      "metadata": {
        "id": "AwU_cEr4vEcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the values of Y(dependent variable) on the basis of test data\n",
        "\n",
        "Y_pred_ridge = ridge_regressor.predict(X_test)\n",
        "# Adding one column in test dataframe to see the difference between actual and predicted values\n",
        "\n",
        "test_df['Ridge Predicted Closing Price'] = Y_pred_ridge\n",
        "ridge_df = test_df.loc[:,['Actual Closing Price','Ridge Predicted Closing Price']]\n",
        "ridge_df.tail(5)\n",
        "     \n"
      ],
      "metadata": {
        "id": "6hQ-7dmKvVru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserting metrices for Ridge Regression CV\n",
        "evaluation_metrices_df.loc[i,\"Model_Name\"]='Ridge Regression CV'\n",
        "\n",
        "# Calling evaluation matrix function for Ridge Regression with Cross validation\n",
        "evaluation_metrics(Y_pred_ridge)\n",
        "i+=1 # i is a incremented variable"
      ],
      "metadata": {
        "id": "ShfX8f_GvkI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call plot graph function to see the  difference in actual vs predicted values\n",
        "\n",
        "plot_graph(Y_pred_ridge)"
      ],
      "metadata": {
        "id": "TFlhD6k2vnp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "GridSearchCV hyperparameter optimization technique use.\n",
        "\n",
        "Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity.It shrinks coefficients toward zero, but they rarely reach zero.\n"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge Regression with Cross Validation model predicted the close price with **0.032** Mean Squared Error.\n",
        "\n",
        "R^2 tell us that independent variable is able to describe **83.42%** of dependent variable\n",
        "\n",
        "Adjusted R^2 is approximately **82.45%**\n",
        "\n",
        "Mean Absolute Percentage Error is **0.0922 %**\n",
        "\n",
        "Very slight change in prediction even after applying CV"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Elastic Net using Cross Validation"
      ],
      "metadata": {
        "id": "4NUkaf93wTrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Elastic Net with CV\n",
        "# Elastic Net is a combination of Lasso and Ridge regression \n",
        "\n",
        "elastic = ElasticNet()  # Creating object \n",
        "\n",
        "# estimating different alpha values and cross validation(cv) value is 5\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100],'l1_ratio':[0.3,0.4,0.5,0.6,0.7,0.8]}\n",
        "elastic_regressor = GridSearchCV(elastic, parameters, scoring='neg_mean_squared_error',cv=5)\n",
        "elastic_regressor.fit(X_train, Y_train)\n",
        "     \n"
      ],
      "metadata": {
        "id": "V0DGdAmpwSbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Algorithm\n",
        "# Finding bext alpha  and l1 ratio value to fit the model\n",
        "\n",
        "print(\"The best fit alpha value is found out to be :\" ,elastic_regressor.best_params_)\n",
        "print(\"\\nUsing \",elastic_regressor.best_params_, \" the negative mean squared error is: \", elastic_regressor.best_score_)"
      ],
      "metadata": {
        "id": "LrG_M8oPwzko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the values of Y(dependent variable) on the basis of test data\n",
        "\n",
        "Y_pred_elastic = elastic_regressor.predict(X_test)\n",
        "     # Adding one column in test dataframe to see the difference between actual and predicted values\n",
        "\n",
        "test_df['Elastic Net Predicted Closing Price'] = Y_pred_elastic\n",
        "relastic_cv_df = test_df.loc[:,['Actual Closing Price','Elastic Net Predicted Closing Price']]\n",
        "relastic_cv_df.head(5)\n",
        "     "
      ],
      "metadata": {
        "id": "3bkgpcmqxGPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inserting metrices for Elastiv Net CV\n",
        "evaluation_metrices_df.loc[i,\"Model_Name\"]='Elastiv Net CV'\n",
        "\n",
        "# Calling evaluation matrix function for Elastic Net with Cross validation\n",
        "evaluation_metrics(Y_pred_elastic)\n",
        "i+=1 # i is a incremented variable"
      ],
      "metadata": {
        "id": "97FVk5WBxNOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call plot graph function to see the  difference in actual vs predicted values\n",
        "\n",
        "plot_graph(Y_pred_elastic)\n"
      ],
      "metadata": {
        "id": "SFsnh2ycxVvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "gyojmkUmgcSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ElasticNet regression is a combination of Lasso regression and Ridge regression.\n",
        "\n",
        "Hyperparameter:Are parameters whose values control the learning process and determine the values of model parameters that a learning algorithm ends up learning. For eg, alpha, cv"
      ],
      "metadata": {
        "id": "QgPNZ-0DgeUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "4y5s6MCfhQny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic Net using Cross Validation model predicted the close price with     **0.032**Mean Squared Error.\n",
        "\n",
        "R^2 tell us that independent variable is able to describe **83.36%** of dependent variable\n",
        "\n",
        "Adjusted R^2 is approximately **82.40%**\n",
        "\n",
        "Mean Absolute Percentage Error is **0.0922 %**"
      ],
      "metadata": {
        "id": "hZa_JQeyhTsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-Neighbor Regressor"
      ],
      "metadata": {
        "id": "mVZ8zHh0FD-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN regression is a non-parametric method that, in an intuitive manner, approximates the association between independent variables and the continuous outcome by averaging the observations in the same neighbourhood."
      ],
      "metadata": {
        "id": "53JvToZcFamn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import K-NeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "#Setup arrays to store training and test accuracies\n",
        "neighbors = np.arange(1,9)\n",
        "train_accuracy =np.empty(len(neighbors))\n",
        "test_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "for i,k in enumerate(neighbors):\n",
        "    # Setup a knn classifier with k neighbors\n",
        "    knn = KNeighborsRegressor(n_neighbors=k)\n",
        "    \n",
        "    # Fit the model\n",
        "    knn.fit(X_train, Y_train)\n",
        "    \n",
        "    # Compute accuracy on the training set\n",
        "    train_accuracy[i] = knn.score(X_train, Y_train)\n",
        "    \n",
        "    # Compute accuracy on the test set\n",
        "    test_accuracy[i] = knn.score(X_test, Y_test) \n"
      ],
      "metadata": {
        "id": "8m-z7kbRFCWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate plot\n",
        "\n",
        "plt.title('k-NN Varying number of neighbors')\n",
        "plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
        "plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_MDivgbOFXG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a knn classifier with k-neighbors\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "     "
      ],
      "metadata": {
        "id": "avxbGZpcFW3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "knn.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "ht0OeVI8FWq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn.score(X_test,Y_test)"
      ],
      "metadata": {
        "id": "1jkGXTDjFWdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us get the predictions using the regressor we had fit above\n",
        "Y_pred_knn = knn.predict(X_test)\n",
        "     "
      ],
      "metadata": {
        "id": "yx1oYcbGF4sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding one column in test dataframe to see the difference between actual and predicted values\n",
        "\n",
        "test_df['KNN Predicted Closing Price'] = Y_pred_knn\n",
        "KNN_df = test_df.loc[:,['Actual Closing Price','KNN Predicted Closing Price']]\n",
        "KNN_df.head(5)\n",
        "     "
      ],
      "metadata": {
        "id": "Gm5TBPt9F4fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserting metrices for KNeighbour Regressor\n",
        "evaluation_metrices_df.loc[i,\"Model_Name\"]='K-Neighbor Regressor'\n",
        "\n",
        "# Calling evaluation matrix function for K-Neighbor Regressor\n",
        "evaluation_metrics(Y_pred_knn)\n",
        "i+=1  # i is a incremented variable\n",
        "     "
      ],
      "metadata": {
        "id": "-Mjb5YVIF4RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call plot graph function to see the  difference in actual vs predicted values\n",
        "\n",
        "plot_graph(Y_pred_knn)"
      ],
      "metadata": {
        "id": "hFcLIqeGFWNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "tABAOu1XG2DY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After implementing Linear Regression:\n",
        "\n",
        "Our KNR model predicted the close price with **0.002** Mean Squared Error.\n",
        "\n",
        "R^2 tell us that independent variable is able to describe **98.49%** of dependent variable\n",
        "\n",
        "Adjusted R^2 is approximately **98.40%**\n",
        "\n",
        "Mean Absolute Percentage Error is **0.0213%**\n",
        "This model performs best among all models"
      ],
      "metadata": {
        "id": "_bPNI2qZGXZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating table of Evaluation Metrices for each model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRpKxEpiyeTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print all records\n",
        "evaluation_metrices_df  "
      ],
      "metadata": {
        "id": "T7YpaVQ9x1hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Over all graphical representation between Actual Closing Price and Predicted Closing Price by All Algorithms\n"
      ],
      "metadata": {
        "id": "RSU00tcdHJYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph between Actual Close price and Predicted Price by All Algorithms\n",
        "\n",
        "test_df.plot(figsize = (15,10))\n",
        "plt.xlabel('Date',fontsize = 14)\n",
        "plt.ylabel('Price (₹)',fontsize = 14)\n",
        "plt.title('Actual closing price vs Predicted Price By All Algorthms',fontweight = 'bold',fontsize = 14)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SRxi4OaiHI7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Neighbor Regressor ML model choose from the above created models as final prediction model because this model shows the better prediction than the other model."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KNR (K-Nearest Neighbors Regression) model is a non-parametric model used for regression analysis. It predicts the value of a target variable by finding the k closest training \n",
        "\n",
        "The KNR model does not make any assumptions about the underlying data distribution, making it a flexible model\n",
        "\n",
        "To understand the feature importance of the KNR model, we can use model explainability tools like SHAP (SHapley Additive exPlanations) values or Permutation Feature Importance. \n",
        "\n",
        "The SHAP values to understand the feature importance of the KNR model, the result could be presented in a summary plot that shows the overall impact of each feature on the model's prediction."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the \n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Variable is strongly dependent on Independent Variables.\n",
        "\n",
        "\n",
        "We have seen that there is neither null nor duplicate values.But Date feature have values of object data type. So, We converted it into proper date format YYYY-MM-DD.\n",
        "\n",
        "K-Neighbor Regressor  performing better than other models with adjusted R^2 98.40%  respectively.\n",
        "\n",
        "With the help of visualization ,We have seen that from 2018 onwards there is sudden fall in the stock closing price. It makes sense how severly Rana Kapoor case fraud affected the price of Yes bank stocks.\n",
        "\n",
        "With the help of distribution plot ,We see that our data is positively skewed.So,We apply some kind of transformation i.e. Log Transformation to convert it into a normal distribution.\n",
        "\n",
        "Lasso and Ridge regression models are giving the same result approximately.\n",
        "\n",
        "I have implementsd Cross Validation on different algorithm as CV performs better on small datasets.But, the result is nearly same.\n",
        "\n",
        "In all the models  the accuracy lie within the range of 79 to 80% and there is no such improvement in accuracy score even after hyperparameter tuning.\n",
        "\n",
        "Highest positive correlation in this heatmap are 'Open' and 'High' and highest negative correlation are 'Open' and 'Close' variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}